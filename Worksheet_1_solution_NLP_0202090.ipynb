{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1.\n",
        "with open('quran-simple.txt', 'r', encoding='utf-8') as file:\n",
        "    quran_text = file.read()\n",
        "print(len(quran_text))  # print number of characters in the Qur’an text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV3rMLoxntZy",
        "outputId": "bdbc33ff-eb77-4783-93a2-ecfcb6c3127b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "689411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.\n",
        "import nltk\n",
        "\n",
        "arabic_words = nltk.word_tokenize(quran_text)\n",
        "print(len(arabic_words))  # print number of tokens in the Qur’an"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWeY-uBlrHkh",
        "outputId": "e4f320e0-9880-4eb4-8eaa-491161bdf62a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.\n",
        "unique_arabic_words = set(arabic_words)\n",
        "print(len(unique_arabic_words))  # print number of unique words in the Qur’an"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66NO3cStToG",
        "outputId": "f1c7365c-edc6-4b47-ff4e-af89b52954fc"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.\n",
        "def lexical_diversity(text):\n",
        "    return len(set(text)) / len(text)\n",
        "\n",
        "arabic_ld = lexical_diversity(arabic_words)\n",
        "print(arabic_ld)  # print the lexical diversity of the Qur’an’s vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzzA5AjctWQF",
        "outputId": "da78a977-724b-452c-a36f-067947ac8fe7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.22460221100389802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "fdist_arabic = FreqDist(arabic_words)\n",
        "with open('quran_frequency_distribution.txt', 'w', encoding='utf-8') as file:\n",
        "    for word, frequency in fdist_arabic.most_common(10):\n",
        "        file.write(f\"{word}: {frequency}\\n\")\n",
        "print(fdist_arabic.most_common(10))  # print the top 10 words and their frequency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sou1A89FtYRv",
        "outputId": "0ea49473-bfcb-490b-a9be-2bf0fbb358ee"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('مِنْ', 1673), ('فِي', 1185), ('مَا', 1010), ('اللَّهِ', 940), ('لَا', 812), ('الَّذِينَ', 810), ('اللَّهُ', 733), ('مِنَ', 693), ('عَلَى', 670), ('إِلَّا', 662)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Read the English text file and store the text in a variable\n",
        "with open('en.pickthall.txt', 'r', encoding='utf-8') as file:\n",
        "    English_quran_text = file.read()\n",
        "print(len(English_quran_text))  # print number of characters in the Qur’an text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9S7c2B_udt7",
        "outputId": "54505150-a748-4eb8-e9bb-e5338d048db5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "828439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the English text, store the tokens in a list, and do the following:\n",
        "English_words = nltk.word_tokenize(English_quran_text)\n",
        "print(len(English_words))  # print number of tokens in the Qur’an"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n7uld45vPZG",
        "outputId": "e5f0287c-7bc3-4094-fcb1-f55120d9c454"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the number of unique words in the English text\n",
        "unique_English_words = set(English_words)\n",
        "print(len(unique_English_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7TOd3J_vUdC",
        "outputId": "bd4e1531-f17b-48ff-b08d-272d675845d4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the number of tokens (words) in the English text\n",
        "print(len(English_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpUo99QUvXHv",
        "outputId": "3fa161d6-6031-4b97-e1a6-554268f6be81"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "183536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the lexical diversity of the English text\n",
        "English_Id = lexical_diversity(English_words)\n",
        "print(English_Id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0WznRgNvYrz",
        "outputId": "f7d36f34-8799-41f5-ed7b-031c4c79976b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.037316929648679276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the frequency distribution of the English text\n",
        "fdist_English = FreqDist(English_words)\n",
        "with open('English_quran_frequency_distribution.txt', 'w', encoding='utf-8') as file:\n",
        "    for word, frequency in fdist_English.most_common(10):\n",
        "        file.write(f\"{word}: {frequency}\\n\")\n",
        "print(fdist_English.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AkMMVVDvZ7G",
        "outputId": "ce92be05-f766-4ff6-d062-3b4f3e9fbc1c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(',', 8213), ('.', 7470), ('the', 7379), ('and', 5546), ('of', 4838), ('is', 3095), (')', 2974), ('(', 2973), ('Allah', 2914), ('they', 2527)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.\n",
        "\n",
        "Comparing the results, we can see that:\n",
        "\n",
        "The Quran text in Arabic has less characters than the English translation of the Quran, with 689411 characters in Arabic compared to 828439 characters in English.\n",
        "\n",
        "The number of tokens in Arabic is also less than in English, with 78245 tokens in Arabic compared to 183536 tokens in English.\n",
        "\n",
        "\n",
        "The number of unique words in Arabic is higher than in English, with 17574 unique words in Arabic compared to 6849 unique words in English.\n",
        "\n",
        "\n",
        "The lexical diversity of the Quran's vocabulary is less in English than in Arabic, with a lexical diversity of 0.037 in English compared to 0.224 in Arabic. This means that the vocabulary in the Arabic Quran is less varied than in the English translation.\n",
        "\n",
        "\n",
        "The frequency distribution of the top 10 words is also different in Arabic and English, with \"مِنْ\" (and) being the most frequent word in Arabic and \"the\" being the most frequent word in English."
      ],
      "metadata": {
        "id": "piTmkhsf0JdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# 8. Define a function to remove short vowels and diacritics from Arabic words\n",
        "def remove_short_vowels_and_diacritics(word):\n",
        "    \"\"\"\n",
        "    A function that removes short vowels and diacritics from an Arabic word.\n",
        "    \"\"\"\n",
        "    # Define a regular expression pattern to match all diacritic characters\n",
        "    pattern = re.compile('[\\u064B-\\u0652]')\n",
        "    \n",
        "    # Use the pattern to remove all diacritic characters from the word\n",
        "    non_vowelized_word = re.sub(pattern, '', word)\n",
        "    \n",
        "    return non_vowelized_word\n",
        "\n",
        "# 9. Read the Arabic Quran text file and store the text in a variable\n",
        "with open('quran-simple.txt', 'r', encoding='utf8') as f:\n",
        "    quran_text = f.read()\n",
        "\n",
        "# Tokenize the Quran text into words and store the words in a list\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "quran_words = nltk.word_tokenize(quran_text)\n",
        "\n",
        "# Convert the list of words to a set to get the number of unique words\n",
        "quran_unique_words = set(quran_words)\n",
        "\n",
        "# Calculate the number of unique words and the lexical diversity\n",
        "quran_unique_word_count = len(quran_unique_words)\n",
        "quran_lexical_diversity = len(quran_words) / quran_unique_word_count\n",
        "\n",
        "# Compute the frequency distribution of words in the Quran and print the top 10 words\n",
        "from nltk import FreqDist\n",
        "quran_freq_dist = FreqDist(quran_words)\n",
        "print(quran_freq_dist.most_common(10))\n",
        "\n",
        "# Generate a list of non-vowelized forms for all words in the Quran\n",
        "quran_non_vowelized = [remove_short_vowels_and_diacritics(word) for word in quran_words]\n",
        "\n",
        "# Convert the list of non-vowelized forms to a set to get the number of unique words\n",
        "quran_unique_non_vowelized = set(quran_non_vowelized)\n",
        "\n",
        "# Calculate the number of unique words and the lexical diversity of the non-vowelized forms\n",
        "quran_unique_non_vowelized_count = len(quran_unique_non_vowelized)\n",
        "quran_lexical_diversity_non_vowelized = len(quran_non_vowelized) / quran_unique_non_vowelized_count\n",
        "\n",
        "# Compute the frequency distribution of non-vowelized words in the Quran and print the top 10 words\n",
        "quran_freq_dist_non_vowelized = FreqDist(quran_non_vowelized)\n",
        "print(quran_freq_dist_non_vowelized.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ulhp6-8voy3",
        "outputId": "596f657b-8ed0-4150-bd57-4359adaeeff0"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('مِنْ', 1673), ('فِي', 1185), ('مَا', 1010), ('اللَّهِ', 940), ('لَا', 812), ('الَّذِينَ', 810), ('اللَّهُ', 733), ('مِنَ', 693), ('عَلَى', 670), ('إِلَّا', 662)]\n",
            "[('من', 2763), ('الله', 2265), ('في', 1185), ('ما', 1010), ('إن', 966), ('لا', 812), ('الذين', 810), ('على', 670), ('إلا', 664), ('ولا', 658)]\n"
          ]
        }
      ]
    }
  ]
}